{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4de23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load known points CSV\n",
    "known_csv = \"climada_output_01.csv\"  # Change to actual file path\n",
    "df_known = pd.read_csv(known_csv)\n",
    "\n",
    "# Load target points CSV\n",
    "target_csv = \"assets.csv\"  # Change to actual file path\n",
    "df_target = pd.read_csv(target_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure required columns exist\n",
    "if \"Latitude\" not in df_target.columns or \"Longitude\" not in df_target.columns:\n",
    "    raise ValueError(\"Target CSV must contain 'Latitude' and 'Longitude' columns.\")\n",
    "\n",
    "# Convert latitude & longitude to Point geometry\n",
    "df_target[\"geometry\"] = df_target.apply(lambda row: Point(row[\"Longitude\"], row[\"Latitude\"]), axis=1)\n",
    "\n",
    "# Save and reload target file (optional, avoids potential formatting issues)\n",
    "df_target.to_csv(\"assets_coords.csv\", index=False)\n",
    "df_target = pd.read_csv(\"assets_coords.csv\")\n",
    "\n",
    "# Parse WKT geometry in known points\n",
    "df_known[\"geometry\"] = df_known[\"geometry\"].apply(lambda x: loads(x).coords[0])  # Convert WKT to (x, y)\n",
    "\n",
    "# Convert target points to (x, y) tuples\n",
    "df_target[\"geometry\"] = df_target.apply(lambda row: (row[\"Longitude\"], row[\"Latitude\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50684af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the nearest known point for a given target\n",
    "def find_nearest(target_point):\n",
    "    df_known[\"distance\"] = df_known[\"geometry\"].apply(lambda x: distance.euclidean(target_point, x))\n",
    "    nearest_row = df_known.loc[df_known[\"distance\"].idxmin()]\n",
    "    return nearest_row.drop([\"geometry\", \"distance\"])  # Drop extra columns\n",
    "\n",
    "# Apply function and **expand results into separate columns**\n",
    "df_nearest = df_target[\"geometry\"].apply(find_nearest).apply(pd.Series)\n",
    "\n",
    "# Merge nearest values back into target DataFrame\n",
    "df_result = df_target.drop(columns=[\"geometry\"]).join(df_nearest)\n",
    "\n",
    "df_result.columns = [\"Name\", \"SBU\", \"Latitude\", \"Longitude\", \"1-min MSW 10 yr RP\", \"1-min MSW 20 yr RP\", \"1-min MSW 50 yr RP\", \"1-min MSW 100 yr RP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the column names you want to round\n",
    "columns_to_round = [\"1-min MSW 10 yr RP\", \"1-min MSW 20 yr RP\", \"1-min MSW 50 yr RP\", \"1-min MSW 100 yr RP\"]\n",
    "# Apply \"round half up\" while preserving NaNs\n",
    "df_result[columns_to_round] = df_result[columns_to_round].apply(\n",
    "    lambda col: np.floor(col + 0.5) if col.dtype.kind in 'fc' else col\n",
    ").astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define percent changes for the 75th percentile future projections\n",
    "percent_changes_75p = {\n",
    "    \"4.5\": {\"2025-2035\": 0.0203, \"2035-2045\": 0.0279, \"2045-2055\": 0.0351},\n",
    "    \"8.5\": {\"2025-2035\": 0.0237, \"2035-2045\": 0.0355, \"2045-2055\": 0.0493}\n",
    "}\n",
    "\n",
    "# Identify all 1-min MSW RP columns (not just 100 yr)\n",
    "rp_columns = [col for col in df_result.columns if \"1-min\" in col and \"yr RP\" in col]\n",
    "if not rp_columns:\n",
    "    raise ValueError(\"No '1-min ... yr RP' columns found!\")\n",
    "\n",
    "# Initialize result dataframe with identifiers\n",
    "result_df = df_result[[\"Name\", \"SBU\", \"Latitude\", \"Longitude\"]].copy()\n",
    "\n",
    "# Process each RP column\n",
    "for rp_col in rp_columns:\n",
    "    # Add base/current values\n",
    "    rp_label = rp_col.replace(\"1-min MSW \", \"\")  # e.g. \"100 yr RP\"\n",
    "    base_col_name = f\"{rp_label}_Current\"\n",
    "    result_df[base_col_name] = df_result[rp_col]\n",
    "\n",
    "    # Loop through each scenario/year and apply percent changes\n",
    "    for scenario, years in percent_changes_75p.items():\n",
    "        for year, pct in years.items():\n",
    "            col_name = f\"{rp_label}_RCP{scenario}_{year}\"\n",
    "            adjusted_values = df_result[rp_col] * (1 + pct)\n",
    "\n",
    "            # Round half up while keeping NaNs\n",
    "            adjusted_values = adjusted_values.apply(\n",
    "                lambda x: np.floor(x + 0.5) if pd.notnull(x) else pd.NA\n",
    "            )\n",
    "            result_df[col_name] = adjusted_values.astype(\"Int64\")\n",
    "\n",
    "# Save the compiled current climate and future climate exposure data to a single CSV\n",
    "result_df.to_csv(\"tc_exposure_results.csv\", index=False)\n",
    "print(\"Saved: Compiled current and 75th percentile future projections\")\n",
    "\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
